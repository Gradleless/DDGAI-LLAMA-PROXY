# **Llama API Server**

A lightweight, modular, and TypeScript-powered HTTP server for managing Llama-based API requests by using duckduckgo AI. The server is designed to be simple, scalable, and easy to maintain. It's not finished.

## **Features**
- ðŸš€ **Blazing Fast**: Built with Node.js's core `http` module, ensuring minimal overhead and maximum performance compared to frameworks like Express or Fastify. Perfect for high-performance applications. (And I wanted to try it)
- ðŸš€ **TypeScript Support**: Strong typing for better development experience.  
- ðŸ§© **Modular Design**: Each route is in its own file for easy readability and extension.  
- ðŸ’¬ **Real-Time Streaming**: Supports Server-Sent Events (SSE) for chat interactions.  
- ðŸ”§ **Extensible**: Add new endpoints by creating a new route file and can easily add another AI provider.

# Disclaimer

This project is for educational purposes only. The author does not take responsibility for how this code is used, deployed, or modified. Please use this project responsibly and in accordance with applicable laws and regulations.
